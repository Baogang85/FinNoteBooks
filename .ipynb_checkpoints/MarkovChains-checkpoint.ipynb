{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729c3da7-c0c7-40c0-9d0a-0a2fa52f9c91",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PYTHON VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aea9e98-5719-40e3-ba3f-7522d3fe6b78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.4 (main, Jul  5 2023, 13:45:01) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134491d-708a-46a9-bfd1-6b5ccbfefad3",
   "metadata": {
    "tags": []
   },
   "source": [
    "This library contains the finite Markov chain *simulator* **`MarkovChain`**. \n",
    "\n",
    "\n",
    "1. How to create a new chain.\n",
    "2. How to simulate the steps of the chain in state space.\n",
    "\n",
    "Make sure the file **`simple_markov_chain_lib`** is in the same folder as this notebook.\n",
    "\n",
    "It is worth opening it up and taking a look, especially at the \"internal methods\" `_partial_sums` and `_next_state` (the underscore `_` at the beginning indicates that they are internal methods and should not be called by the user). You can find the code by clicking on this [link](/edit/simple_markov_chain_lib.py). \n",
    "\n",
    "### Example\n",
    "\n",
    "The cell below simulates the first 10 steps of a chain moving through state space \n",
    "$X = \\{0, 1, 2, 3, 4\\}$ with a state transition probability matrix:\n",
    "\n",
    "$$\n",
    "P = \n",
    "\\begin{pmatrix}\n",
    "0 & 1/2 & 1/2 & 0 & 0 \\\\\n",
    "1/3 & 0 & 0 & 2/3 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 \\\\\n",
    "1/2 & 0 & 0 & 1/2 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "and initial distribution: \n",
    "\n",
    "$$ \\pi_0 = (1, 0, 0, 0, 0, 0 ) $$\n",
    "\n",
    "That is, the chain starts from state 0 (1st line) with probability 1."
   ]
  },
  {
   "cell_type": "raw",
   "id": "48536677-3291-4076-8b76-77991c7b7fb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "from simple_markov_chain_lib import markov_chain  # import markov chain simulator\n",
    "\n",
    "# Transition Table\n",
    "markov_table = {\n",
    "    0: {1: .5, 2: .5},  # from state 0 we move to state 1 with prob 0.5 and to state 2 with 0.5\n",
    "    1: {0: 1/3, 3: 2/3},\n",
    "    2: {2: 1.},\n",
    "    3: {0: .5, 3: .5},\n",
    "    4: {4: 1.}\n",
    "}\n",
    "\n",
    "# Initial Distribution\n",
    "init_dist = {0: 1.}  # we start from state 0 with probability 1\n",
    "\n",
    "mc = markov_chain(markov_table, init_dist)\n",
    "\n",
    "mc.start()\n",
    "print(\"At time {} the chain is in state {}\".format(mc.steps, mc.running_state))\n",
    "for i in range(10):\n",
    "    mc.move()\n",
    "    print(\"At time {} the chain is in state {}\".format(mc.steps, mc.running_state))\n",
    "### Creating a new Markov chain\n",
    "\n",
    "To create a new Markov chain we need to give the simulator 2 arguments:\n",
    "\n",
    "1. `markov_table`: the transition probability table of the chain and\n",
    "2. `init_dist` (optional): the initial distribution of the chain.\n",
    "\n",
    "#### Transition probability table (`markov_table`)\n",
    "# Transition Table\n",
    "markov_table = {\n",
    "    0: {1: .5, 2: .5},  # from state 0 we move to state 1 with prob 0.5 and to state 2 with 0.5\n",
    "    1: {0: 1/3, 3: 2/3},\n",
    "    2: {2: 1.},\n",
    "    3: {0: .5, 3: .5},\n",
    "    4: {4: 1.}\n",
    "}\n",
    "Often the transition tables are \"sparse\", most of the time\n",
    "we only write the non-zero ones.\n",
    "\n",
    "Each and every \"internal\" dictionary (`dict`) describes a probability mass function as follows:\n",
    "\n",
    "* `key` = state (not necessarily e a number)\n",
    "* `value` = probability (must be a number in the range $[0, 1]$)\n",
    "\n",
    "Those states **not** contained in the dictionary are considered to have zero probability.\n",
    "The state space is defined by the keys of the \"external\" dictionary (in our example `0, 1, 2, 3, 4`).\n",
    "\n",
    "#### Initial distribution (`init_dist`)\n",
    "\n",
    "The initial distribution is defined in a similar way as the probability mass function.\n",
    "# Initial Distribution\n",
    "init_dist = {0: 1.}  # we start from state 0 with probability 1\n",
    "### Random Walk in the State Space\n",
    "\n",
    "#### Start\n",
    "\n",
    "Now that we have the chain we can start exploring the state space.\n",
    "To begin, we need to start our walk. This is done with the command **``start`**.\n",
    "mc.start()\n",
    "After the walk is initiated we can extract from the created Markov chain 2 pieces of information.\n",
    "\n",
    "1. **`steps`**: what step is it in ($n$ in $\\{X_n\\}_{n \\in \\mathbb{N}_0}$).\n",
    "2. **`running_state`**: what state ($X_n$) is in\n",
    "\n",
    "By executing the next cell you will see what step the chain is in.\n",
    "mc.steps\n",
    "mc.running_state\n",
    "#### Move\n",
    "\n",
    "To move around inside the state space we need to run the command **`move`**.\n",
    "mc.move()\n",
    "This command increments the time (`steps`) by one and moves the chain to one of the possible transition states\n",
    "#### Walk\n",
    "\n",
    "So the code below simulates the first 10 steps of the chain:\n",
    "mc.start()\n",
    "for i in range(10):\n",
    "    print(\"At time {} the chain is in state {}\".format(mc.steps, mc.running_state))\n",
    "    mc.move()\n",
    "\n",
    "print(\"At time {} the chain is in state {}\".format(mc.steps, mc.running_state))\n",
    "## Application\n",
    "\n",
    "This exercise uses the Monte Carlo method to estimate the probability of the **example** above for $p = \\frac{1}{6}$.\n",
    "\n",
    "To simulate the problem we will need:\n",
    "\n",
    "1. Load the `markov_chain` simulator from the `simple_markov_chain_lib.py` file.\n",
    "2. Create the transition probability matrix and the initial distribution.\n",
    "3. Create a new chain.\n",
    "\n",
    "These steps are implemented in the following code cell:\n",
    "import random\n",
    "random.seed(2018)  # for reproducibility\n",
    "\n",
    "p = 1/6\n",
    "\n",
    "# A dictionary for the initial distibution. \n",
    "# We prescribe the initial distribution\n",
    "init_probs = {1: 1.0} \n",
    " \n",
    "# A dictionary for the transition probability  matrix. \n",
    "# Every state-key corresponds to a list with tuples of (Next_State,Probability) \n",
    "markov_table = {\n",
    "    1: {2: 1.},\n",
    "    2: {2: 2/3, 3: 1/3},\n",
    "    3: {1: p, 2: 1-p}\n",
    "}\n",
    " \n",
    "# Ok... we are ready know\n",
    "# Let's construct a Markov Chain. So let's call the constructor\n",
    "mc = markov_chain(markov_table, init_probs)\n",
    "Making use of the **`mc`** chain we can move on to simulations.\n",
    "\n",
    "Specifically, we will estimate the probability $\\mathbb{P}_1[X_{40}=1]=\\mathbb{P}\\left[X_{40} = 1\\mid X_0 = 1\\right]$. \n",
    "To do this, we will run the chain many times (parameter `N`) always starting from state `1` and count how many times the chain was in state `1` after `40` steps (parameter `steps`), i.e. how many times the event $X_{40}=0$ occurred. Each time we execute the **`for`** loop below we get an independent sample of r.v. $Y$ which has value 1 if $X_{40}=1$, and value 0 if $X_{40}\\neq 1$. The law of large numbers yields:\n",
    "$$ \\lim_{N\\to\\infty}\\frac{Y_1+\\cdots+Y_N}{N}=\\mathbb{E}_1[Y]=\\mathbb{P}_1[X_{40}=1].$$\n",
    "Therefore, when `N` is large, the percentage of times in which the event $${X_{40}=1}$$ occurred is a good estimate of the probability $$\\mathbb{P}_1[X_{40}=1]$$. The quantity $\\hat{p}_N$ called `phat` in the code below is as the Monte Carlo estimator of the probability $\\mathbb{P}_1[X_{40}=1]$.\n",
    "## Experiment parameters\n",
    "N = 1000     # number of samples\n",
    "steps = 40   # the target time\n",
    "counter = 0  # to count the number of times the event {X_40  = 0} occurs\n",
    "\n",
    "## Simulation\n",
    "for i in range(N):\n",
    "    mc.start()  # new experiment\n",
    "    for j in range(steps):  mc.move()\n",
    "    if mc.running_state == 1:  counter += 1\n",
    "\n",
    "phat = counter / N\n",
    "\n",
    "print(\n",
    "    \"\"\"\n",
    "    We executed {0} times the first {1} steps of the markov chain\n",
    "    and we captured the running state in state one {2} times.\n",
    "    So we estimate the Pr[X_{1} = 1 | X_0 = 1] to be {3}\n",
    "    \"\"\".format(N, steps, counter, phat)\n",
    ")\n",
    "\n",
    "Unlike the numerical estimators encountered in Numerical Analysis, $\\hat{p}_N$ is a random variable. That checks out by rerunning the previous cell a few (10) times. \n",
    "\n",
    "The next piece of code generates a list of 100 samples from the standard normal distribution and calculates the sample mean and variance. \n",
    "import statistics as stat ## import the library statistics. We will use it to compute the mean and variance of our list\n",
    "estimates=[] ## create the empty list estimates.\n",
    "for i in range(100): estimates.append(random.gauss(0,1)) \n",
    "    ## in each of 100 runs generate a sample from the standard normal distribution and append it to the list estimates\n",
    "print(\n",
    "    \"\"\" \n",
    "    The sample mean is {0:.5f} and the sample variance is {1:.5f}\n",
    "    \"\"\".format(stat.mean(estimates), stat.variance(estimates))\n",
    ")\n",
    "    ## compute the SAMPLE mean and variance of the elements in our list keeping only 5 decimal digits\n",
    "## Example\n",
    "\n",
    "In this example the variation of the absorption time of a Markov chain is studied.\n",
    "In the cell below a Markov chain in the state space $\\mathbb{X} = \\{0, 1, 2, 3, 4\\}$ is created, with a transition probability matrix\n",
    "\n",
    "$$\n",
    "P = \n",
    "\\begin{pmatrix}\n",
    "2/5 & 1/2 & 1/10 & 0 & 0 \\\\\n",
    "1/3 & 0 & 0 & 2/3 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 \\\\\n",
    "1/2 & 1/8 & 0 & 1/4 & 1/8 \\\\\n",
    "0 & 0 & 0 & 0 & 1 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "and initial distribution: \n",
    "\n",
    "$$ \\pi_0 = (1, 0, 0, 0, 0, 0 ) .$$\n",
    "# Transition Table\n",
    "markov_table = {\n",
    "    0: {1: .5, 2: .5},  # from state 0 we move to state 1 with prob 0.5 and to state 2 with 0.5\n",
    "    1: {0: 1/3, 3: 2/3},\n",
    "    2: {2: 1.},\n",
    "    3: {0: .5, 3: .25, 4: .25},\n",
    "    4: {4: 1.}\n",
    "}\n",
    "\n",
    "# Initial Distribution\n",
    "init_dist = {0: 1.}  # we start from state 0 with probability 1\n",
    "\n",
    "mc = markov_chain(markov_table, init_dist)\n",
    "Obviously states `2` and `4` are \"absorbing\". \n",
    "The `mc` chain can be used to estimate the absorption time of the chain.\n",
    "\n",
    "The Monte Carlo estimator $E_N$ of the absorption time is the average of the absorption times in these $N$ samples.\n",
    "sample_size = 2 ** 5  # Ν\n",
    "running_total = 0\n",
    "\n",
    "for i in range(sample_size):\n",
    "    mc.start()\n",
    "    while mc.running_state != 2 and mc.running_state != 4:\n",
    "        mc.move()\n",
    "    running_total += mc.steps  # steps it took to be absorbed\n",
    "\n",
    "mc_estimate = running_total / sample_size\n",
    "print(\"The estimated absorption time is %.2f steps\" % mc_estimate)\n",
    "Remember that the estimator $E_N$ is a random variable. The purpose of this exercise is to find out computationally how the variance of $E_N$ is affected by the number of iterations $N$. It is expected that as $N$ grows the variance of $E_N$ falls, but this relationship can also be understood quantitatively.\n",
    "## Application\n",
    "\n",
    "Computation of the variance of the estimator $E_N$ for $N$ (`sample_size`) $2^5, \\dots, 2^{12}$ and plotting of the graph of the function $Var(E_N)$ in normal and logarithmic scales. Wherever a line appears, an estimation of its slope is calculated.\n",
    "import numpy as np  # numerical computations library. We will call it np in our code\n",
    "import matplotlib.pyplot as plt  # library for plotting. We will call it plt in our code\n",
    "\n",
    "# Transition Table\n",
    "markov_table = {\n",
    "    0: {0: 2/5, 1: .5, 2: .1                },  # from state 0 we move to state 1 with prob 0.5 and to state 2 with 0.5\n",
    "    1: {0: 1/3,               3: 2/3        },\n",
    "    2: {               2: 1.                },\n",
    "    3: {0: .5,                3: .25, 4: .25},\n",
    "    4: {                              4: 1. }\n",
    "}\n",
    "\n",
    "# Initial Distribution\n",
    "init_dist = {0: 1.}  # we start from state 0 with probability 1\n",
    "\n",
    "mc = markov_chain(markov_table, init_dist)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "M             = 30\n",
    "estimates     = []\n",
    "x             = []\n",
    "y             = []\n",
    "\n",
    "for k in range(5,12,1):\n",
    "    sample_size   = 2 ** k  # Ν\n",
    "    x.append(sample_size)\n",
    "    for j in range(M):\n",
    "        running_total = 0\n",
    "        for i in range(sample_size):\n",
    "            mc.start()\n",
    "            while mc.running_state != 2 and mc.running_state != 4:\n",
    "                mc.move()\n",
    "            running_total += mc.steps  # steps it took to be absorbed\n",
    "\n",
    "        mc_estimate = running_total / sample_size\n",
    "        estimates.append(mc_estimate)  # array of length M, including the estimated absortion time of M iterations\n",
    "    print(\"\"\" The sample variance is {0:.5f} \"\"\".format(stat.variance(estimates))) # print the Var for each and every sample size\n",
    "    y.append(stat.variance(estimates))\n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "# Plots\n",
    "plt.figure() \n",
    "\n",
    "# Right Axes\n",
    "plt.subplot(1, 2, 1)  \n",
    "plt.plot(x, y)\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Var')\n",
    "plt.title('Linear Axis')\n",
    "plt.grid(True)  \n",
    "\n",
    "# Left Axes\n",
    "plt.subplot(1, 2, 2) # select the 2nd subplot\n",
    "plt.loglog(x, y, basex=2, basey=2)\n",
    "plt.xlabel('logN')\n",
    "plt.ylabel('logVar')\n",
    "plt.title('Log-log Axis')\n",
    "plt.grid(True)\n",
    "#--------------------------------------------------------------------------\n",
    "# Υπολογισμος κλισης προσεγγιστικα. \n",
    "from math import log\n",
    "import matplotlib.pyplot as plt\n",
    "z = np.polyfit([log(x1,2) for x1 in x],[log(y1,2) for y1 in y],1)\n",
    "print(\"The slope of the straight line is: \", z[0])\n",
    "<UL>\n",
    "<LI>Given any equation of the form $$y=ax^k,$$ by taking the logarithm (of any base) of that equation we obtain\n",
    "$$logy = klogx + loga.$$ However, by setting $X = logx$ and $Y = logy$ we obtain: $$Y = mX + b$$, where $m = k$ and $b = loga$, which is an equation of a straight line.</LI>\n",
    "\n",
    "<LI>\n",
    "After the above transformation, we obtain the equation: $$Y = mX + b$$, we have that $m = $k is the slope of the graph and $b = loga$ is the point of intersection with the $logy$ $(logx = 0)$ axis.</LI>\n",
    "\n",
    "<LI>\n",
    "The slope in the case: $$y=8x^3$$ is equal to 3 and in the case $$y=8x^2$$ is equal to 2 (it is equal to the exponents, respectively). The following block code aims to substantiate this claim.</LI>\n",
    "</UL>\n",
    "## Linear Regression\n",
    "\n",
    "Numerical approximation of the slope of $$y=32x^3$$ in log-scale.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#--------------------------------------------------------------------------\n",
    "start, end, step = 0.01, 6.0, 0.01\n",
    "x = np.arange(start, end, step)  # x = [0.01, 0.02, ..., 5.99, 6.00]\n",
    "# Compute f(x) = 32 * x^3 for every element of x\n",
    "y = 32 * x**3\n",
    "#--------------------------------------------------------------------------\n",
    "plt.figure()\n",
    "\n",
    "# Right Axes\n",
    "plt.subplot(1, 2, 1)  # setup subplots 1-row, 2-cols, select the 1st\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('32*x^3')\n",
    "plt.title('Linear Axis')\n",
    "plt.grid(True)  # add grid-lines\n",
    "\n",
    "# Left Axes\n",
    "plt.subplot(1, 2, 2) # select the 2nd subplot\n",
    "plt.loglog(x, y, basex=2, basey=2)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('32*x^3')\n",
    "plt.title('Log-log Axis')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.5)  # specify the width space\n",
    "#--------------------------------------------------------------------------\n",
    "# Παρατηρουμε πως η κλιση υπολογιζεται ιση με 3 οπως ακριβως αναμενεται. \n",
    "from math import log\n",
    "import matplotlib.pyplot as plt\n",
    "z = np.polyfit([log(x1,2) for x1 in x],[log(y1,2) for y1 in y],1)\n",
    "print(\"The slope of the straight line is: \", z[0])\n",
    "# to plot the results in the notebook:\n",
    "%matplotlib inline\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Create a list of real numbers from start to end by step\n",
    "start, end, step = 0.01, 6.0, 0.01\n",
    "x1 = np.arange(start, end, step)  # x1 = [0.01, 0.02, ..., 5.99, 6.00]\n",
    "x2 = np.arange(start, end, step)\n",
    "# Compute f(x) = 8 * x^3 & f(x) = 8 * x^2 for every element of x\n",
    "y1 = 8 * x1**3\n",
    "y2 = 8 * x2**2\n",
    "#------------------------------------------------------------------------------------------\n",
    "plt.figure(figsize=(12, 7))  # define figure size\n",
    "\n",
    "# Linear\n",
    "plt.subplot(2, 2, 1)  # setup subplots 1-row, 2-cols, select the 1st\n",
    "plt.plot(x1, y1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('8*x^3')\n",
    "plt.title('Linear Axis')\n",
    "plt.grid(True)  # add grid-lines\n",
    "\n",
    "# Logarithmic\n",
    "plt.subplot(2, 2, 2) # select the 2nd subplot\n",
    "plt.loglog(x1, y1, basex=2, basey=2)\n",
    "plt.xlabel('log(x)')\n",
    "plt.ylabel('log(8*x^3)')\n",
    "plt.title('Log-log Axis')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.5)  # specify the width space\n",
    "#------------------------------------------------------------------------------------------\n",
    "plt.figure(figsize=(12, 7))  # define figure size\n",
    "\n",
    "# Linear\n",
    "plt.subplot(2, 2, 3)  # setup subplots 1-row, 2-cols, select the 3rd\n",
    "plt.plot(x2, y2)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('8*x^2')\n",
    "plt.title('Linear Axis')\n",
    "plt.grid(True)  # add grid-lines\n",
    "\n",
    "# Logarithmic\n",
    "plt.subplot(2, 2, 4) # select the 4th subplot\n",
    "plt.loglog(x2, y2, basex=2, basey=2)\n",
    "plt.xlabel('log(x)')\n",
    "plt.ylabel('log(8*x^2)')\n",
    "plt.title('Log-log Axis')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.5)  # specify the width space\n",
    "![Markov Chain of Tennis Game](https://pbs.twimg.com/media/DpqZm0mW4AAxuWM.jpg)\n",
    "## Appllication \n",
    "\n",
    "Using *Monte Carlo* an estimation is given for the probability of the serving player (`Player A`) to win, if the probability of him winning each point is $p = 0.6$. \n",
    "random.seed(2018)  \n",
    "from simple_markov_chain_lib import markov_chain\n",
    "x = []\n",
    "y = []\n",
    "# range command inputs must be integers, later i will divide p with a 100...\n",
    "for p1 in range(2, 100, 2):\n",
    "    \n",
    "    p = p1/100.0\n",
    "    x.append(p)\n",
    "    init_probs = {2: p, 3: 1-p} \n",
    "\n",
    "    ## A wins at state 11(B wins at state 15)\n",
    "    markov_table = {\n",
    "        1 : {2 : p , 3 : 1-p},\n",
    "        2 : {4 : p , 5 : 1-p},\n",
    "        3 : {5 : p , 6 : 1-p},\n",
    "        4 : {7 : p , 8 : 1-p},\n",
    "        5 : {8 : p , 9 : 1-p},\n",
    "        6 : {9 : p , 10: 1-p},\n",
    "        7 : {11: p , 12: 1-p},\n",
    "        8 : {12: p , 13: 1-p},\n",
    "        9 : {13: p , 14: 1-p},\n",
    "        10: {14: p , 15: 1-p},\n",
    "        11: {11: 1          },\n",
    "        12: {11: p , 16: 1-p},\n",
    "        13: {16: p , 17: 1-p},\n",
    "        14: {15: p , 17: 1-p},\n",
    "        15: {15: 1          },\n",
    "        16: {11: p , 18: 1-p},\n",
    "        17: {15: 1-p , 18: p},\n",
    "        18: {19: p , 20: 1-p},\n",
    "        19: {11: p , 18: 1-p},\n",
    "        20: {18: p , 15: 1-p}\n",
    "    \n",
    "    }\n",
    " \n",
    "    mc = markov_chain(markov_table, init_probs)\n",
    "    \n",
    "    N       = 1000     \n",
    "    steps   = 40   \n",
    "    counter = 0     \n",
    "\n",
    "    for i in range(N):\n",
    "        mc.start()  \n",
    "        for j in range(steps):  mc.move()\n",
    "        if mc.running_state == 11:  counter += 1\n",
    "\n",
    "    phat = counter / N\n",
    "    y.append(phat)\n",
    " \n",
    "# Let's plot (x,y)\n",
    "plt.figure()\n",
    "plt.plot(x, y)\n",
    "# Specify some extra attributes\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('phat')\n",
    "plt.title('Tennis (A wins)');      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd27bfb-168c-4a15-8bd3-16040b70d2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
